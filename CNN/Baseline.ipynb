{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2895e9af-f64a-401f-ba8d-d5416bb4908f",
   "metadata": {},
   "source": [
    "7-параметрическая задача по определению концентрации ионов $Cu^{2+}$', '$Ni^{2+}$', '$Pb^{2+}$', '$Co^{2+}$', '$Al^{3+}$', '$Cr^{3+}$', '$NO_3^-$ по спектрам ФЛ УТ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2cb37e4d-5f3a-4b15-9481-1c3cd190c073",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "#import tensorflow as tf\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import median_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.model_selection import KFold\n",
    "import random\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "from itertools import chain\n",
    "import pandas as pd \n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import trange\n",
    "import datetime\n",
    "from torcheval.metrics import R2Score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e826ed0-cc2d-464a-a0a7-1308388614b7",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "916b0776-f321-4eba-bce9-64d6eacf38d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CDs_2D_dataset(Dataset):\n",
    "    def __init__(self, annotations_file, spec_dir, transform=None, target_transform=None):\n",
    "      '''annotations_file - the file which contains lables of the samples included in training/validation/test sets'''\n",
    "      self.spec_labels = pd.read_csv(annotations_file, sep=',', decimal=\",\").iloc[:,1:] # labels (concentrations for 4 ions) for all the samples from annotation file (Y_ions.csv)\n",
    "      self.spec_number = pd.read_csv(annotations_file, sep=',', decimal=\",\").iloc[:,0] # numbers for all the samples from annotation file (Y_ions.csv)\n",
    "      self.spec_dir = spec_dir # folder where csv files are located\n",
    "      self.transform = transform \n",
    "      self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.spec_labels)#length of the dataset\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label = self.spec_labels.iloc[idx] # get the label of the sample via sample's index\n",
    "        \n",
    "        sp = np.array(pd.read_csv(self.spec_dir + str(self.spec_number[idx])+'.csv').T.iloc[1:,:], dtype='float32') # get the EEM of the sample via sample's index\n",
    "        #sp = np.array(pd.read_csv(self.spec_dir + str(self.spec_number[idx])+'_CorrectionData'+'.csv', skiprows=38, sep=';', decimal=\",\").T.iloc[1:-1,:], dtype='float32') # get the EEM of the sample via sample's index\n",
    "\n",
    "        sp[sp<0]=0 # here we zero negative values of intensities\n",
    "        spec = torch.from_numpy(sp).unsqueeze(0) # add dimension for channels of cnn\n",
    "        \n",
    "        if self.transform:\n",
    "            spec = self.transform(spec)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "            \n",
    "        return spec, torch.from_numpy(np.array(label, dtype='float32')) # return spectrum and corresponding labels\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4a9a1af1-e31f-4dde-a453-427eb7d009a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1 1 7\n",
      "tensor([[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 0.0000, 20.4750,  0.0000,  ...,  0.2660,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.3290,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]])\n",
      "torch.Size([1, 201, 27])\n",
      "tensor([[ 3.0000,  3.0000,  4.5000,  6.0000,  6.0000,  1.5000, 55.5000]])\n"
     ]
    }
   ],
   "source": [
    "# file_x = '/Users/galinacugreeva/Desktop/УТ 7 параметров/CD_HM_dataset/'#1000_CorrectionData.csv'\n",
    "# file_y = '/Users/galinacugreeva/Desktop/УТ 7 параметров/CD_HM_dataset/Y_ions.csv'\n",
    "\n",
    "file_x = '../CD_HM_dataset/'\n",
    "file_y = '../CD_HM_dataset/Y_ions.csv'\n",
    "\n",
    "training_data =  CDs_2D_dataset(file_y, file_x)\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=1, shuffle=True)\n",
    "\n",
    "# смотреть на размерности\n",
    "for i, j in train_dataloader:\n",
    "    print(i.shape[0], i.shape[1], j.shape[0], j.shape[1])\n",
    "    print(i[0]), print(i[0].shape)\n",
    "    print(j)\n",
    "    break\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7585bec1-dc0d-41a3-bc00-1f9171beca03",
   "metadata": {},
   "source": [
    "## Calculate mean and std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "945ac695-b87c-472a-9fde-a8e5c8e26628",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_std(train_dataloader):\n",
    "    mean = 0.0\n",
    "    for specs, _ in train_dataloader:\n",
    "        batch_samples = specs.size(0) \n",
    "        specs = specs.view(batch_samples, specs.size(1), -1)\n",
    "        mean += specs.mean(2).sum(0)\n",
    "    mean = mean / len(train_dataloader.dataset)\n",
    "\n",
    "    var = 0.0\n",
    "    for specs, _ in train_dataloader:\n",
    "        batch_samples = specs.size(0)\n",
    "        specs = specs.view(batch_samples, specs.size(1), -1)\n",
    "        var += ((specs - mean.unsqueeze(1))**2).sum([0,2])\n",
    "    #std = torch.sqrt(var / (len(train_dataloader.dataset)*500*41))\n",
    "    std = torch.sqrt(var / (len(train_dataloader.dataset)*200*27))\n",
    "\n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad5246e-0142-4fe2-a4e8-eca7f2e23adf",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5768c6-0540-4cc1-92f0-1bb37afcf94e",
   "metadata": {},
   "source": [
    "## Useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e6bc3760-a729-4065-8e30-30bb0390ab35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_weights(m):\n",
    "    '''\n",
    "    Try resetting model weights to avoid weight leakage.\n",
    "    '''\n",
    "    for layer in m.children():\n",
    "        if hasattr(layer, 'reset_parameters'):\n",
    "            print(f'Reset trainable parameters of layer = {layer}')\n",
    "            layer.reset_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fe5b5816-8e03-4880-aca0-5498b1f5ad5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_predictions(N, model_name, split_path, optimizer, dataloader, dset):\n",
    "    \n",
    "    #load the model\n",
    "    checkpoint = torch.load(split_path + 'model'+model_name+'.pth')\n",
    "    N.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    #load optimizer\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    \n",
    "    last_best_epoch = checkpoint['epoch'] #the epoch with minimum loss function that occured during training\n",
    "    loss = checkpoint['loss']\n",
    "    N.eval()\n",
    "\n",
    "    y_ae = np.zeros((1,7))\n",
    "    y_ae_true = np.zeros((1,7))\n",
    "    \n",
    "    #write the outputs of the model\n",
    "    for specs, labels in dataloader:\n",
    "        outputs = N(specs) # get the outputs from the network\n",
    "        outputs[outputs<0]=0 #we zero negative outputs as they are impossible for concentration values\n",
    "        ae = outputs.detach().numpy()\n",
    "        ae_true = labels.detach().numpy()\n",
    "        #np.concatenate((y_ae, ae), axis=0)\n",
    "        y_ae = np.concatenate((y_ae, ae), axis=0) # columns with networks's output for the dataloader\n",
    "        y_ae_true = np.concatenate((y_ae_true, ae_true), axis=0) # columns with true output for the dataloader\n",
    "\n",
    "    a = ['Cu','Ni', 'Pb', 'Al', 'Co', 'Cr','NO3']\n",
    "    #a = ['pH']\n",
    "    pd.DataFrame(y_ae).to_csv(split_path + 'Y_out_'+'_'+dset+'.csv',sep=',', header = a)\n",
    "    pd.DataFrame(y_ae_true).to_csv(split_path + 'Y_true_'+'_'+dset+'.csv',sep=',', header = a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a6009559-afd4-4336-9746-4c130c384ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def calculate_metrics(model, loader):\n",
    "    \n",
    "    for specs, targets in loader:\n",
    "        preds = model(specs)\n",
    "        preds[preds<0]=0\n",
    "    \n",
    "        loss_mae = nn.L1Loss()\n",
    "        mae = loss_mae(preds, targets)\n",
    "    \n",
    "        loss_rmse = nn.MSELoss()\n",
    "        rmse = loss_rmse(preds, targets)**0.5\n",
    "    \n",
    "        r2 = R2Score()\n",
    "        r2.update(preds, targets)\n",
    "        r2 = r2.compute()\n",
    "    \n",
    "    return mae, rmse, r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75885db0-fb1e-43b4-a008-f4ac84968db9",
   "metadata": {},
   "source": [
    "# 1. Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a36bb602-9114-4f42-85fb-15b13fb0599b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_path = 'C:/Users/Liquid_Lab/Desktop/7-параметрическая задача УТ/' \n",
    "\n",
    "case_name = '6_2DCNN_str5_32neur_leakyrelu' + '_' + str(datetime.date.today())\n",
    "#for cat in ['Cu', 'Cr', 'Ni', 'anions']:\n",
    "cnn_2d_path = case_name+'/'#+cat+'/'\n",
    "\n",
    "Y = pd.read_csv(gen_path+'CD_HM_dataset/'+'Y_ions'+'.csv', sep=',')\n",
    "\n",
    "\n",
    "k_folds = [[42,12],[612,45],[72,172]] \n",
    "\n",
    "# for fold in k_folds:\n",
    "#     split_path = gen_path+cnn_2d_path+'split_'+ str(fold[0])+'_'+str(fold[1])+ '/'\n",
    "#     os.makedirs(split_path, exist_ok=True)\n",
    "\n",
    "#     Y_trn, Y_30 = train_test_split(Y, test_size=0.3, random_state=fold[0])\n",
    "#     Y_vld, Y_tst = train_test_split(Y_30, test_size = 0.3333, random_state=fold[1])\n",
    "\n",
    "#     a = ['sample_number','Cu','Ni', 'Pb', 'Al', 'Co', 'Cr','NO3']\n",
    "\n",
    "#     pd.DataFrame(Y_trn).to_csv(split_path + 'Y_trn'+'.csv',sep=',', index=False, header = a)\n",
    "#     pd.DataFrame(Y_vld).to_csv(split_path + 'Y_vld'+'.csv',sep=',', index=False, header = a)\n",
    "#     pd.DataFrame(Y_tst).to_csv(split_path + 'Y_tst'+'.csv',sep=',', index=False, header = a)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1964caa5-b6b8-4ebd-ac11-1d172d268c31",
   "metadata": {},
   "source": [
    "# wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eb2fc5e0-d094-4167-842f-8abcccaa9765",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.login()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e18834-6e6f-4b44-8a35-53c179491bfd",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2c79b6a0-9403-4cff-910d-458a64b179c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, lr, l2_lambda, k_folds, case_name, mnozh_init, epochs_num):\n",
    "\n",
    "    print('Start in', str(datetime.datetime.now()))\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print('Using device:', device)\n",
    "        \n",
    "    loss_function = torch.nn.MSELoss().cuda()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    \n",
    "    for fold in k_folds:\n",
    "        \n",
    "        split_path = gen_path+cnn_2d_path+'split_'+ str(fold[0])+'_'+str(fold[1])+ '/'\n",
    "\n",
    "        training_data = CDs_2D_dataset(split_path+'Y_trn'+'.csv',gen_path + 'CD_HM_dataset/')\n",
    "        train_dataloader = DataLoader(training_data, batch_size=256, shuffle=True)\n",
    "        mean, std = mean_std(train_dataloader)\n",
    "    \n",
    "        #Data import and normalization Basic\n",
    "    \n",
    "        training_data = CDs_2D_dataset(split_path+'Y_trn'+'.csv', gen_path + 'CD_HM_dataset/', transform= transforms.Compose([transforms.Normalize(mean, std)]))\n",
    "    \n",
    "        validation_data = CDs_2D_dataset(split_path+'Y_vld'+'.csv', gen_path + 'CD_HM_dataset/', transform= transforms.Compose([transforms.Normalize(mean, std)]))\n",
    "        test_data = CDs_2D_dataset(split_path+'Y_tst'+'.csv', gen_path + 'CD_HM_dataset/', transform= transforms.Compose([transforms.Normalize(mean, std)]))\n",
    "    \n",
    "        train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
    "        validation_dataloader = DataLoader(validation_data, batch_size=64, shuffle=True)\n",
    "        test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)\n",
    "\n",
    "        print(mean, std)\n",
    "\n",
    "    \n",
    "        for init_number in range(0, mnozh_init): #Это я делаю множественную инициализацию весов сети\n",
    "    \n",
    "            init_path = split_path + str(init_number)+'/'\n",
    "            os.makedirs(init_path, exist_ok=True)\n",
    "    \n",
    "            test_stop = 100 #stopping criterion\n",
    "            max_val_loss = 10000.0\n",
    "\n",
    "            wandb.init(project = case_name)\n",
    "        \n",
    "            split_name = 'split_'+ str(fold[0])+'_'+str(fold[1])\n",
    "            init_name = '_' + str(init_number)\n",
    "            model_name = '_2D_CNN'\n",
    "\n",
    "            wandb.run.name = split_name + init_name + model_name+'_reg_'+str(l2_lambda)\n",
    "            wandb.run.save()\n",
    "    \n",
    "            for epoch_step in range(0, epochs_num, test_stop):\n",
    "                \n",
    "                if epoch_step!=0:\n",
    "                    checkpoint = torch.load(init_path + 'model'+model_name+'.pth')\n",
    "                    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "                    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "                    last_best_epoch = checkpoint['epoch']\n",
    "                    loss = checkpoint['loss']\n",
    "                    model.train()\n",
    "                    \n",
    "                    if last_best_epoch + test_stop > ep:\n",
    "                        for ep in range(epoch_step, epoch_step+test_stop):\n",
    "                            for _, data in enumerate(train_dataloader, 0): # get bacth\n",
    "                                inputs, labels = data # parse batch\n",
    "                                optimizer.zero_grad() # sets the gradients of all optimized tensors to zero.\n",
    "                                outputs = model(inputs) # get outputs\n",
    "\n",
    "                                loss = loss_function(outputs, labels) # calculate loss\n",
    "                                l2_norm = sum(p.pow(2.0).sum() for p in model.parameters())\n",
    "                                loss = loss + l2_lambda * l2_norm\n",
    "                                loss.backward() # calculate gradients\n",
    "                            \n",
    "                                optimizer.step() # performs a single optimization step (parameter update).\n",
    "    \n",
    "                            dl = 0\n",
    "                            val_loss = 0.0\n",
    "                            for specs, labels in validation_dataloader: \n",
    "                                val_loss += loss_function(model(specs),labels)\n",
    "                                dl+=1\n",
    "                            val_loss = val_loss/dl\n",
    "                            \n",
    "                            if val_loss.item() <= max_val_loss:\n",
    "                                torch.save({'epoch': ep,\n",
    "                                  'model_state_dict': model.state_dict(),\n",
    "                                  'optimizer_state_dict': optimizer.state_dict(),\n",
    "                                  'loss': loss}, init_path + 'model'+model_name+'.pth')\n",
    "                                max_val_loss = val_loss.item()\n",
    "                            wandb.log({\"trn_loss\": loss, \"vld_loss\": val_loss})\n",
    "\n",
    "                    else: continue    \n",
    "                print(epoch_step)\n",
    "                if epoch_step==0:\n",
    "                    model.apply(reset_weights)\n",
    "    \n",
    "                    for ep in range(epoch_step, test_stop):\n",
    "                        for _, data in enumerate(train_dataloader, 0): # get bacth\n",
    "                            inputs, labels = data # parse batch\n",
    "                            optimizer.zero_grad() # sets the gradients of all optimized tensors to zero.\n",
    "                            outputs = model(inputs) # get outputs\n",
    "                            loss = loss_function(outputs, labels) # calculate loss\n",
    "                            loss.backward() # calculate gradients\n",
    "                            optimizer.step() # performs a single optimization step (parameter update).\n",
    "    \n",
    "                        dl = 0\n",
    "                        val_loss = 0.0\n",
    "                        for specs, labels in validation_dataloader:\n",
    "                            val_loss += loss_function(model(specs),labels)\n",
    "                            dl+=1\n",
    "                        val_loss = val_loss/dl\n",
    "    \n",
    "                        if val_loss.item() <= max_val_loss:\n",
    "                            torch.save({'epoch': ep,\n",
    "                              'model_state_dict': model.state_dict(),\n",
    "                              'optimizer_state_dict': optimizer.state_dict(),\n",
    "                              'loss': loss}, init_path + 'model'+model_name+'.pth')\n",
    "                            max_val_loss = val_loss.item()\n",
    "                        wandb.log({\"trn_loss\": loss, \"vld_loss\": val_loss})\n",
    "    \n",
    "            write_predictions(model, model_name, init_path, optimizer, train_dataloader, dset = 'trn')\n",
    "            write_predictions(model, model_name, init_path, optimizer, validation_dataloader, dset ='vld')\n",
    "            write_predictions(model, model_name, init_path, optimizer, test_dataloader, dset ='tst')\n",
    "\n",
    "            trn_metrics = calculate_metrics(model, train_dataloader)\n",
    "            vld_metrics = calculate_metrics(model, validation_dataloader)\n",
    "            tst_metrics = calculate_metrics(model, test_dataloader)\n",
    "\n",
    "            wandb.log({\"trn_mae\": float(trn_metrics[0]), \"trn_rmse\": float(trn_metrics[1]), \"trn_r2\": float(trn_metrics[2])})\n",
    "            wandb.log({\"vld_mae\": float(vld_metrics[0]), \"vld_rmse\": float(vld_metrics[1]), \"vld_r2\": float(vld_metrics[2])})\n",
    "            wandb.log({\"tst_mae\": float(tst_metrics[0]), \"tst_rmse\": float(tst_metrics[1]), \"tst_r2\": float(tst_metrics[2])})\n",
    "            \n",
    "            wandb.log({\"epoch\": ep})\n",
    "    \n",
    "            wandb.finish()\n",
    "            \n",
    "            print(epoch_step, fold)\n",
    "            print(str(datetime.datetime.now()))\n",
    "            \n",
    "    print('End in', str(datetime.datetime.now()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad904485-9f2d-4132-b58f-7b0a2d0733d4",
   "metadata": {},
   "source": [
    "# 2. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e644e1f0-0dad-4c4a-9c49-88f0ce9924e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class twoD_CNN_new_leakyrelu_32(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__()\n",
    "\n",
    "        self.CNN = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=3, kernel_size=5, stride=5),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.MaxPool2d(2), \n",
    "            nn.Flatten(),\n",
    "            nn.Linear(3 * 20 * 2, 32), \n",
    "            nn.LeakyReLU(), \n",
    "            nn.Linear(32, 7) \n",
    "\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.CNN(x)\n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "05d96f20-10b2-47eb-b332-85cae6a39354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start in 2024-09-06 14:04:33.157493\n",
      "Using device: cuda\n",
      "tensor([34.0707]) tensor([119.0244])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:i164vftx) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>trn_loss</td><td>█▄▆▄▅▄▃▃▃▃▃▂▃▃▂▂▃▃▄▃▂▃▁▃▃▃▂▁▁▃▂▂▄▂▇▃▂▃▁▃</td></tr><tr><td>vld_loss</td><td>█▆▄▄▃▃▃▂▂▂▂▁▁▁▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>trn_loss</td><td>2.83233</td></tr><tr><td>vld_loss</td><td>3.5609</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">smart-firebrand-3</strong> at: <a href='https://wandb.ai/gtchugreeva/6_2DCNN_str5_32neur_leakyrelu_2024-09-05/runs/i164vftx' target=\"_blank\">https://wandb.ai/gtchugreeva/6_2DCNN_str5_32neur_leakyrelu_2024-09-05/runs/i164vftx</a><br/> View project at: <a href='https://wandb.ai/gtchugreeva/6_2DCNN_str5_32neur_leakyrelu_2024-09-05' target=\"_blank\">https://wandb.ai/gtchugreeva/6_2DCNN_str5_32neur_leakyrelu_2024-09-05</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240905_131605-i164vftx\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.9 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:i164vftx). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb9ce8c184d34f14ad6af199cdb24cf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011111111111111112, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Liquid_Lab\\Desktop\\7-параметрическая задача УТ\\6_2DCNN_str5_32neur_leakyrelu_2024-09-05\\wandb\\run-20240906_140503-5dqwd3cu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/gtchugreeva/6_2DCNN_str5_32neur_leakyrelu_2024-09-05/runs/5dqwd3cu' target=\"_blank\">different-wood-4</a></strong> to <a href='https://wandb.ai/gtchugreeva/6_2DCNN_str5_32neur_leakyrelu_2024-09-05' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/gtchugreeva/6_2DCNN_str5_32neur_leakyrelu_2024-09-05' target=\"_blank\">https://wandb.ai/gtchugreeva/6_2DCNN_str5_32neur_leakyrelu_2024-09-05</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/gtchugreeva/6_2DCNN_str5_32neur_leakyrelu_2024-09-05/runs/5dqwd3cu' target=\"_blank\">https://wandb.ai/gtchugreeva/6_2DCNN_str5_32neur_leakyrelu_2024-09-05/runs/5dqwd3cu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Reset trainable parameters of layer = Conv2d(1, 3, kernel_size=(5, 5), stride=(5, 5))\n",
      "Reset trainable parameters of layer = Linear(in_features=120, out_features=32, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=32, out_features=7, bias=True)\n",
      "100\n",
      "200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Network error resolved after 0:01:54.347833, resuming normal operation.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Network error resolved after 0:00:41.435756, resuming normal operation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>trn_loss</td><td>██▆▇▅▄▃▄▄▄▅▄▃▃▂▃▃▃▁▃▄▂▅▂▆▄▂▁▂▃▃▃▃▂▃▂▂▃▄▄</td></tr><tr><td>trn_mae</td><td>▁</td></tr><tr><td>trn_r2</td><td>▁</td></tr><tr><td>trn_rmse</td><td>▁</td></tr><tr><td>tst_mae</td><td>▁</td></tr><tr><td>tst_r2</td><td>▁</td></tr><tr><td>tst_rmse</td><td>▁</td></tr><tr><td>vld_loss</td><td>█▆▅▄▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▂▁▁▁▁▁▂▁▁▁▁▁▂▁▁▁</td></tr><tr><td>vld_mae</td><td>▁</td></tr><tr><td>vld_r2</td><td>▁</td></tr><tr><td>vld_rmse</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>2299</td></tr><tr><td>trn_loss</td><td>4.16926</td></tr><tr><td>trn_mae</td><td>1.20949</td></tr><tr><td>trn_r2</td><td>0.61658</td></tr><tr><td>trn_rmse</td><td>1.78653</td></tr><tr><td>tst_mae</td><td>1.04683</td></tr><tr><td>tst_r2</td><td>0.70166</td></tr><tr><td>tst_rmse</td><td>1.50212</td></tr><tr><td>vld_loss</td><td>3.49399</td></tr><tr><td>vld_mae</td><td>1.37598</td></tr><tr><td>vld_r2</td><td>0.56074</td></tr><tr><td>vld_rmse</td><td>1.81519</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">different-wood-4</strong> at: <a href='https://wandb.ai/gtchugreeva/6_2DCNN_str5_32neur_leakyrelu_2024-09-05/runs/5dqwd3cu' target=\"_blank\">https://wandb.ai/gtchugreeva/6_2DCNN_str5_32neur_leakyrelu_2024-09-05/runs/5dqwd3cu</a><br/> View project at: <a href='https://wandb.ai/gtchugreeva/6_2DCNN_str5_32neur_leakyrelu_2024-09-05' target=\"_blank\">https://wandb.ai/gtchugreeva/6_2DCNN_str5_32neur_leakyrelu_2024-09-05</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240906_140503-5dqwd3cu\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.9 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4900 [612, 45]\n",
      "2024-09-07 04:27:23.406424\n",
      "tensor([34.3572]) tensor([111.3454])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Liquid_Lab\\Desktop\\7-параметрическая задача УТ\\6_2DCNN_str5_32neur_leakyrelu_2024-09-05\\wandb\\run-20240907_042754-9emhw1qx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/gtchugreeva/6_2DCNN_str5_32neur_leakyrelu_2024-09-05/runs/9emhw1qx' target=\"_blank\">decent-surf-5</a></strong> to <a href='https://wandb.ai/gtchugreeva/6_2DCNN_str5_32neur_leakyrelu_2024-09-05' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/gtchugreeva/6_2DCNN_str5_32neur_leakyrelu_2024-09-05' target=\"_blank\">https://wandb.ai/gtchugreeva/6_2DCNN_str5_32neur_leakyrelu_2024-09-05</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/gtchugreeva/6_2DCNN_str5_32neur_leakyrelu_2024-09-05/runs/9emhw1qx' target=\"_blank\">https://wandb.ai/gtchugreeva/6_2DCNN_str5_32neur_leakyrelu_2024-09-05/runs/9emhw1qx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Reset trainable parameters of layer = Conv2d(1, 3, kernel_size=(5, 5), stride=(5, 5))\n",
      "Reset trainable parameters of layer = Linear(in_features=120, out_features=32, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=32, out_features=7, bias=True)\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>trn_loss</td><td>█▇▄▇▂▁▃▂▃▃▁▃▃▃▄▁▂▃▁▂▁▄▂▁▄▁▂▁▃▂▂▂▃▂▃▁▂▆▂▂</td></tr><tr><td>trn_mae</td><td>▁</td></tr><tr><td>trn_r2</td><td>▁</td></tr><tr><td>trn_rmse</td><td>▁</td></tr><tr><td>tst_mae</td><td>▁</td></tr><tr><td>tst_r2</td><td>▁</td></tr><tr><td>tst_rmse</td><td>▁</td></tr><tr><td>vld_loss</td><td>█▆▄▃▃▂▂▂▂▂▂▂▁▁▂▁▁▁▁▁▂▂▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▂</td></tr><tr><td>vld_mae</td><td>▁</td></tr><tr><td>vld_r2</td><td>▁</td></tr><tr><td>vld_rmse</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>1699</td></tr><tr><td>trn_loss</td><td>3.4685</td></tr><tr><td>trn_mae</td><td>1.35636</td></tr><tr><td>trn_r2</td><td>0.50217</td></tr><tr><td>trn_rmse</td><td>1.88844</td></tr><tr><td>tst_mae</td><td>1.27897</td></tr><tr><td>tst_r2</td><td>0.58462</td></tr><tr><td>tst_rmse</td><td>1.63797</td></tr><tr><td>vld_loss</td><td>3.88321</td></tr><tr><td>vld_mae</td><td>1.52729</td></tr><tr><td>vld_r2</td><td>0.48231</td></tr><tr><td>vld_rmse</td><td>2.13615</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">decent-surf-5</strong> at: <a href='https://wandb.ai/gtchugreeva/6_2DCNN_str5_32neur_leakyrelu_2024-09-05/runs/9emhw1qx' target=\"_blank\">https://wandb.ai/gtchugreeva/6_2DCNN_str5_32neur_leakyrelu_2024-09-05/runs/9emhw1qx</a><br/> View project at: <a href='https://wandb.ai/gtchugreeva/6_2DCNN_str5_32neur_leakyrelu_2024-09-05' target=\"_blank\">https://wandb.ai/gtchugreeva/6_2DCNN_str5_32neur_leakyrelu_2024-09-05</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240907_042754-9emhw1qx\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.9 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4900 [72, 172]\n",
      "2024-09-07 15:01:53.968557\n",
      "End in 2024-09-07 15:01:53.968557\n"
     ]
    }
   ],
   "source": [
    "k_folds = [[612,45],[72,172]] \n",
    "\n",
    "train(model=twoD_CNN_new_leakyrelu_32(), \n",
    "      lr=0.001, \n",
    "      l2_lambda = 0.001,\n",
    "      k_folds=k_folds,\n",
    "      case_name=case_name,\n",
    "      mnozh_init=1, \n",
    "      epochs_num=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee83f6b-d359-4f57-858a-c7caed22b36b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d39d6f4-18de-49ad-a929-fee35ee26d3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
